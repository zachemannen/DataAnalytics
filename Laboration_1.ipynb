{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jet0RhBCH6vk"
      },
      "source": [
        "# Laboration 1 - Analys av tweets fr√•n bokm√§ssan\n",
        "\n",
        "## Attribution David Johnsson, Uppsala University"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmQkkVauH6vn"
      },
      "source": [
        "Starta med att ladda in f√∂ljande moduler och s√§tt upp visualiseringsmilj√∂n f√∂r matplotlib\n",
        "\n",
        "1. `pandas` Ett bibliotek f√∂r att hantera data i tabellform, ett av de absolut vanligaste biblioteken f√∂r data analytics.Vi kommer g√• igenom pandas mer senare i kursen.\n",
        "2. `textmining` \n",
        "Funktioner f√∂r statistisk textmining, fokuserad p√• bag-of-words model (som ni inte beh√∂ver s√§tta er in f√∂r denna kurs.f F√∂r den nyfikne eller vetgirige finns enkla f√∂rklaringar exempelvis [h√§r](https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/) eller [h√§r](https://www.geeksforgeeks.org/bag-of-words-bow-model-in-nlp/), en enkel tutorial finns ocks√• [h√§r](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)) \n",
        "3. `wordcloud` - En visualiseringsmodul f√∂r att skapa ordmoln, vilket vi g√∂r i denna laboration.\n",
        "4. `matplotlib` - Ett bibliotek f√∂r att skapa visualiseringar av tabelldata. \n",
        "5. `sklearn` -  Scikit-learn,ett pythonbibliotek f√∂r maskininl√§rningsalgoritmer, den kommer vi anv√§nda mycket i b√•de laboration 3 och 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xJBaizZaH6vo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /Users/margob/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
            "Requirement already satisfied: click in /Users/margob/anaconda3/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/margob/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/margob/anaconda3/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
            "Requirement already satisfied: tqdm in /Users/margob/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install nltk "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NQASGPwvH6vp"
      },
      "outputs": [],
      "source": [
        "# K√∂r denna cell f√∂r att ladda in biblioteken och s√§tta upp v√•r milj√∂\n",
        "import pandas as pd\n",
        "import nltk as tm\n",
        "from nltk.corpus import stopwords\n",
        "import wordcloud\n",
        "import matplotlib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# S√§tt upp visualiseringen\n",
        "%matplotlib inline\n",
        "matplotlib.pyplot.rcParams['figure.figsize'] = [10, 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SdwBMbSYH6vq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/margob/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tm.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2NzG4XofH6vq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'alla',\n",
              " 'allt',\n",
              " 'att',\n",
              " 'av',\n",
              " 'blev',\n",
              " 'bli',\n",
              " 'blir',\n",
              " 'blivit',\n",
              " 'de',\n",
              " 'dem',\n",
              " 'den',\n",
              " 'denna',\n",
              " 'deras',\n",
              " 'dess',\n",
              " 'dessa',\n",
              " 'det',\n",
              " 'detta',\n",
              " 'dig',\n",
              " 'din',\n",
              " 'dina',\n",
              " 'ditt',\n",
              " 'du',\n",
              " 'd√§r',\n",
              " 'd√•',\n",
              " 'efter',\n",
              " 'ej',\n",
              " 'eller',\n",
              " 'en',\n",
              " 'er',\n",
              " 'era',\n",
              " 'ert',\n",
              " 'ett',\n",
              " 'fr√•n',\n",
              " 'f√∂r',\n",
              " 'ha',\n",
              " 'hade',\n",
              " 'han',\n",
              " 'hans',\n",
              " 'har',\n",
              " 'henne',\n",
              " 'hennes',\n",
              " 'hon',\n",
              " 'honom',\n",
              " 'hur',\n",
              " 'h√§r',\n",
              " 'i',\n",
              " 'icke',\n",
              " 'ingen',\n",
              " 'inom',\n",
              " 'inte',\n",
              " 'jag',\n",
              " 'ju',\n",
              " 'kan',\n",
              " 'kunde',\n",
              " 'man',\n",
              " 'med',\n",
              " 'mellan',\n",
              " 'men',\n",
              " 'mig',\n",
              " 'min',\n",
              " 'mina',\n",
              " 'mitt',\n",
              " 'mot',\n",
              " 'mycket',\n",
              " 'ni',\n",
              " 'nu',\n",
              " 'n√§r',\n",
              " 'n√•gon',\n",
              " 'n√•got',\n",
              " 'n√•gra',\n",
              " 'och',\n",
              " 'om',\n",
              " 'oss',\n",
              " 'p√•',\n",
              " 'samma',\n",
              " 'sedan',\n",
              " 'sig',\n",
              " 'sin',\n",
              " 'sina',\n",
              " 'sitta',\n",
              " 'sj√§lv',\n",
              " 'skulle',\n",
              " 'som',\n",
              " 's√•',\n",
              " 's√•dan',\n",
              " 's√•dana',\n",
              " 's√•dant',\n",
              " 'till',\n",
              " 'under',\n",
              " 'upp',\n",
              " 'ut',\n",
              " 'utan',\n",
              " 'vad',\n",
              " 'var',\n",
              " 'vara',\n",
              " 'varf√∂r',\n",
              " 'varit',\n",
              " 'varje',\n",
              " 'vars',\n",
              " 'vart',\n",
              " 'vem',\n",
              " 'vi',\n",
              " 'vid',\n",
              " 'vilka',\n",
              " 'vilkas',\n",
              " 'vilken',\n",
              " 'vilket',\n",
              " 'v√•r',\n",
              " 'v√•ra',\n",
              " 'v√•rt',\n",
              " '√§n',\n",
              " '√§r',\n",
              " '√•t',\n",
              " '√∂ver'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopWords = set(stopwords.words('swedish'))\n",
        "stopWords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNAM61sJH6vq",
        "lang": "en"
      },
      "source": [
        "## Analys av Twitterdata fr√•n bokm√§ssan\n",
        "\n",
        "Ni har blivit inhyrda som konsulter f√∂r en bokpublicist som vill att du ska ta reda p√• vilka teman och b√∂cker som har f√•tt mest uppm√§rksamhet p√• bokm√§ssan i G√∂teborg 2016. \n",
        "\n",
        "Er uppgift √§r att via Twitterdata unders√∂ka vilka √§mnen som f√•tt speciellt mycket uppm√§rksamhet f√∂r och under bokm√§ssan och presentera ett f√∂rslag till f√∂retaget du arbetar med vad som √§r l√§mpliga debatt√§mnen. \n",
        "\n",
        "Fokus h√§r √§r allts√• p√• att f√∂rst√• data, vilket √§r en viktigt del av pre-processering inf√∂r mer avacerad dataanalys. \n",
        "\n",
        "**F1.** Vad f√∂r data √§r distinkt f√∂r twitter och vilken typ av pre-processing tror ni kommer beh√∂vas p√• den typen av data? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIhr9nrQH6vr",
        "lang": "en"
      },
      "source": [
        "## Data processing\n",
        "\n",
        "Som alltid beh√∂ver v√•rt data st√§das, i detta fall √§r fokus att sortera bort data som antingen inte g√•r att analysera eller inte √§r intressant fr√•n den r√•textdata vi f√•tt fr√•n Twitter. Den data som givits samlades in fr√•n Twitter fr√•n maj till september 2016.\n",
        "\n",
        "Er datafil finns i mappen data i laborationsrepositoriet och heter `twitter_book_fair_data.tsv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP3aZwD0H6vs",
        "lang": "en"
      },
      "source": [
        "### Ladda data\n",
        "\n",
        "En `.tsv` fil betyder att det √§r en tab-separerad fil med tabelldata (j√§mf√∂rt med ; separerad som vi anv√§nt tidigare)\n",
        "\n",
        "**F2** Starta arbetet med att l√§sa in filen med read_csv() med f√∂ljande parametrar:  encoding=\"utf-8\", sep=\"\\t\" och spara i en dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOesfIykH6vt",
        "lang": "en"
      },
      "source": [
        "**F3** Inspektera den dataframe som skapats med l√§mpliga funktioner. Ta reda p√• f√∂ljande:\n",
        "\n",
        "Hur ser den ut?\n",
        "Antal kolumner och rader?\n",
        "Datatyper?\n",
        "\n",
        "Gl√∂m inte bort att n√§r du utf√∂r operationer p√• en datafram s√• sparas ingenting om du inte skapar en variabel som du lagrar dina √§ndringar i! (alternativt skriver √∂ver den dataframe du har genom att s√§tta parametern inplace = True (default √§r False)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA70CpnuH6vt"
      },
      "source": [
        "**F4** Finns det nullv√§rden i v√•rt dataset? Varf√∂r/varf√∂r inte?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ4proEGH6vu"
      },
      "source": [
        "**F5.** Hur m√•nga tweets i v√•rt dataset √§r n√§mnanden av andra anv√§ndare (allts√• n√§r `@twittername` finns med i tweeten) \n",
        "\n",
        "*Hint: Det kan vara till hj√§lp att anv√§nda funktionen `info()`*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0aKLENaH6vu",
        "lang": "en"
      },
      "source": [
        "**F6.** En kolumn √§r speciellt intressant f√∂r v√•r **textanalys**, extrahera den fr√•n den dataframe vi lagrat all data i och skapa en variabel d√§r du placerar denna data, d√∂p variablen till `tweets_corpus`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IqBlz-cH6vu",
        "lang": "en"
      },
      "source": [
        "### Emojis\n",
        "\n",
        "P√• Twitter √§r det v√§ldigt vanligt med emojis üëç ‚ú® üê´ üéâ üöÄ ü§ò.\n",
        "\n",
        "Dessa kan inneh√•lla mycket information som kan vara relevant f√∂r v√•r analys. Dock √§r det ofta sv√•rt att analysera emojis med hj√§lp av vanliga verktug f√∂r NLP(Natural Language Processig). \n",
        "\n",
        "Vi beh√∂ver d√§rf√∂r ta bort dessa ur v√•rt utvalda dataset som skapades i uppgiften ovan.\n",
        "\n",
        "F√∂ljande kod utf√∂r detta, ni beh√∂ver inte bry er om lambda just nu, men vi kommer g√• igenom det lite senare i kursen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YyBIdQGBH6vv",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tweets_corpus' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m encode2ascii \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m clean_tweets \u001b[38;5;241m=\u001b[39m tweets_corpus\u001b[38;5;241m.\u001b[39mapply(encode2ascii)\n\u001b[1;32m      3\u001b[0m clean_tweets\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tweets_corpus' is not defined"
          ]
        }
      ],
      "source": [
        "encode2ascii = lambda x: x.encode('ascii', errors='ignore').decode('utf-8')\n",
        "clean_tweets = tweets_corpus.apply(encode2ascii)\n",
        "clean_tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWe2XSDGH6vv",
        "lang": "en"
      },
      "source": [
        "**F7.** Hur p√•verkas kvaliteten p√• v√•r analys potentiellt av att ta bort alla emojis? F√∂rklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJoSEeRJH6vv",
        "lang": "en"
      },
      "source": [
        "### Ta bort URLs\n",
        "Det √§r ocks√• vanligt att man p√• Twitter l√§nkar till olika webbplatser med hj√§lp av URL:er, n√§r man g√∂r textanalys p√• twitterdata √§r det vanligt att delar av dessa URL:er dyker upp som \"mest frekventa ord\" vilket p√•verkar v√•r analys negativs. Dessa beh√∂ver d√§rf√∂r ocks√• tas bort."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS5g0sqNH6vw"
      },
      "outputs": [],
      "source": [
        "clean_tweets = clean_tweets.str.replace(r'http\\S+', '')\n",
        "clean_tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XcXU2UsH6vw"
      },
      "source": [
        "**F8.** Hur kan borttagandet av URL:er pv√•erkar analysen och dess kvalitet, f√∂rklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT69AsyaH6vw",
        "lang": "en"
      },
      "source": [
        "### Funktion f√∂r att hitta mest frekventa ord \n",
        "\n",
        "Ett s√§tt att f√∂rst√• hur olika metoder f√∂r pre-processing p√•verkar ett dataset kan man r√§kna de mest f√∂rekommande orden efter varje operation som utf√∂rs. Eftersom vi kommer vilja utf√∂ra denna r√§kning m√•nga g√•nger under arbetet √§r de l√§mpligt att skapa en funktion f√∂r det som vi kan anropa flera g√•nger.\n",
        "\n",
        "#### Vad √§r en Term Document Matrix (TDM)?\n",
        "\n",
        "En TDM √§r en tabell d√§r antalet unika ord r√§knas f√∂r varje dokument. F√∂r att g√∂ra detta p√• v√•rt Twitterdata √§r det l√§mpligt att skapa en TDM d√§r varje tweet √§r en egen vektor d√§r varje element best√•r av de ord som finns i den tweeten. En tweet med tre unika ord blir allts√• en vektor med tre element. \n",
        "\n",
        "Nedanst√•ende kod skapar denna TDM i form av en funktion med namn `create_term_document_matrix()`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z18BDBGH6vw"
      },
      "source": [
        "**F9** Koden nedan √§r inte kommenterad, l√§gg in kommentarer som f√∂rklarar vad som sker i koden. (No hittar dokumentationen f√∂r CountVectorizer() [h√§r](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) och en kort beskrivning med exempel [h√§r](https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEnz4QawH6vx"
      },
      "outputs": [],
      "source": [
        "def create_term_document_matrix(corpus, min_df=1):\n",
        "    cvec = CountVectorizer(min_df=min_df, stop_words=stopWords)\n",
        "    tfmatrix = cvec.fit_transform(corpus)\n",
        "    return pd.DataFrame(data=tfmatrix.toarray(), columns=cvec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILk1ovrXH6vx"
      },
      "source": [
        "**F10** Testa v√•r nya funktion genom att skapa en TDM endast f√∂r de tre f√∂rsta raderna i `clean_tweets` som kan sorteras ut med `.head(3)` funktionen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh_fE-55H6vx"
      },
      "outputs": [],
      "source": [
        "#kod h√§r..\n",
        "create_term_document_matrix( )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkrRfQbvH6vx"
      },
      "source": [
        "**F11.** Hur m√•nga kolumner skapades i TDM:n med bara 3 av raderna i v√•rt corpus?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhEHvqMwH6vx"
      },
      "source": [
        "F√∂r att hitta de mest frekvent f√∂rekommander orden i v√•r TDM beh√∂ver vi r√§kna ord. Det √§r ocks√• l√§mpligt med en visualisering √∂ver dessa vanligast f√∂rekommande ord. √Ñven detta kommer vi beh√∂va g√∂ra flera g√•nger och d√§rf√∂r √§r det √•terigen l√§mpligt att definiera en funktion `plot_top_words()` som b√•de r√§knar och plottar orden i ett stapeldiagram. \n",
        "\n",
        "**F12** I nedanst√•ende cell √§r funktionen definierad, men koden √§r √•terigen inte kommenterad, skapa kommentarer (eller skriv i en markdowncell) som f√∂rklarar vad funktionen g√∂r. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLDvz6oJH6vy"
      },
      "outputs": [],
      "source": [
        "def plot_top_words(tweets, num_word_instances, top_words):\n",
        "    tdm_df = create_term_document_matrix(tweets, min_df=2)\n",
        "    word_frequencies = tdm_df[[x for x in tdm_df.columns if len(x) > 1]].sum()\n",
        "    sorted_words = word_frequencies.sort_values(ascending=False)\n",
        "    top_sorted_words = sorted_words[:num_word_instances]\n",
        "    top_sorted_words[:top_words].plot.bar()\n",
        "    return top_sorted_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHXVAeU4H6vy"
      },
      "source": [
        "Nu kan vi anv√§nda `plot_top_words()` funktionen f√∂r att r√§kna ut de mest f√∂rekommande orden i hela v√•rt corpus, viktigt att ha t√•lamod dock f√∂r det kan ta ett tag. Nedanst√•ende kod utf√∂r ber√§kningen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBmexWnYH6vy"
      },
      "outputs": [],
      "source": [
        "top_words = plot_top_words(clean_tweets, 50, 30)\n",
        "top_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVzNG0aGH6vy"
      },
      "source": [
        "**F13** Hur m√•nga g√•nger m√•ste ett ord finnas i corpuset f√∂r att finnas med i resultatet `top_words` s√• som koden √§r skriven ovan?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98pedQ7FH6vy"
      },
      "source": [
        "**F14.** Hur m√•nga ord plottas i stapeldiagrammet? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8qJSdH3H6vy",
        "lang": "en"
      },
      "source": [
        "### Sm√• bokst√§ver\n",
        "\n",
        "N√§sta steg i pre-processingen av v√•rt dataset (v√•rt corpus) √§r att g√∂ra om alla bokst√§ver till sm√•. \n",
        "\n",
        "**F15** \n",
        "\n",
        "a.Utf√∂r √§ndringen att alla stora bokst√§ver blir sm√• bokst√§ver i `clean_tweets` och spara i en ny variabel kallad `tweets_lowered`\n",
        "\n",
        "b.Varf√∂r vill man g√∂ra det f√∂r v√•r analys?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJh2s1G-H6vz"
      },
      "source": [
        "**F16** R√§kna ut en ny variabel med de mest f√∂rekommander (frekventa) orden, d√∂p den till `top_words_lowered`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nks3SNKsH6vz",
        "outputId": "ab43ffbd-b40c-4bfe-c279-5ac346b7f0ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Skriv klart denna kodcell f√∂r F1.16\n",
        "\n",
        "top_words_lowered = ...\n",
        "top_words_lowered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H03xRSXhH6v0"
      },
      "source": [
        "**F17.** Har n√•got f√∂r√§ndrats, vad? F√∂rklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZypjpLC3H6v0",
        "lang": "en"
      },
      "source": [
        "F√∂r att underl√§tta att j√§mf√∂ra vad v√•ra anstr√§ngningar f√•r f√∂r resultat kan det vara bra att enkelt kunna j√§mf√∂ra olika listor med top_words.\n",
        "\n",
        "**F18 a** Skapa en ny dataframe som har tv√• kolumner, en med de 20 mest frekventa orden fr√•n`top_words` och en med de 20 mest frekventa orden fr√•n `top_word_lowered`. D√∂p kolumnerna till `Top tweeted clean`och  `Top tweeted lowered`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avEK_LiSH6v0"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\n",
        "    'Top tweeted clean': top_words[0:20].index,\n",
        "    'Top tweeted lowered': top_words_lowered[0:20].index\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9mkXeekH6v0",
        "lang": "en"
      },
      "source": [
        "**F18 b** Ett annnat s√§tt att g√∂ra ungef√§r samma sak, fast lite mer automatiskt √§r nedanst√•ende kod som ocks√• j√§mf√∂r de f√∂rsta 20 orden. G√∂r om den s√• att den ist√§llet f√∂r att j√§mf√∂ra de 20 mest frekventa orden, j√§mf√∂r de ord som √§r **minst** f√∂rekommande i de tv√• listorna `top_words`och `top_words_lowered`.\n",
        "\n",
        "**F19** Vad returnerar nedanst√•ende kodrad om de tv√• listor som j√§mf√∂rs √§r identiska? Vad returneras om de inte √§r identiska?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1cgrM_vH6v0"
      },
      "outputs": [],
      "source": [
        "set(top_words[0:20].index) - set(top_words_lowered[0:20].index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bILAEd4H6v0"
      },
      "source": [
        "### Korta ord\n",
        "\n",
        "Korta ord har ofta inte n√•gon egentlig betydelse, allts√• beh√∂ver vi inte dessa ord. Typiska s√•dana ord kan vara ja, jo eller nej. Vi best√§mmer oss f√∂r att alla ord som √§r kortare √§n 3 bokst√§ver inte innehar n√•gon betydelse i v√•r analys och tar d√§rmed bort dem. \n",
        "\n",
        "**F20** Ta bort alla ord med f√§rre bokst√§ver √§n 3(HINT: [regular expressions](https://docs.python.org/3/howto/regex.html)), l√§gg den nya listan med ord (som inte inneh√•ller ord med f√§rre bokst√§ver √§n 3) i en variabel med namn `tweets_low_no_small`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W_yn-ZeH6v1"
      },
      "outputs": [],
      "source": [
        "tweets_low_no_small = ...#din kod h√§r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94XWyjSkH6v1"
      },
      "outputs": [],
      "source": [
        "#Skapar ny topplista utan korta ord\n",
        "top_words_low_no_small = plot_top_words(tweets_low_no_small, 50, 30)\n",
        "top_words_low_no_small"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqXEMg93H6v1"
      },
      "source": [
        "**F21.** Efter att korta ord tagits bort, hur m√•nga g√•nger m√•ste ett ord f√∂rekomma i v√•rt corpus f√∂r att hamna i den nya listan enligt ovan? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYOtnuIAH6v1",
        "lang": "en"
      },
      "source": [
        "### Betydelsel√∂sa ord\n",
        "\n",
        "Stop words √§r andra ord som inte √§r korta men som √§nd√• inte har betydelse, dessa kan vara lite besv√§rligare att identifiera och ta bort. En m√∂jlighet √§r att helt enkelt skapa en lista med s√•dana ord och sedan anv√§nda den listan f√∂r att filtrera ut orden ur ett corpus. Vi har ju redan tagit bort alla ord med f√§rre bokst√§ver √§n 3, s√• s√•dana beh√∂ver vi inte l√§gga in i listan. \n",
        "\n",
        "Nedan √§r ett exempel p√• en lista med stoppord som √§r betydelsel√∂sa. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pAICOjgH6v1"
      },
      "outputs": [],
      "source": [
        "my_stop_words = [\"och\", \"det\", \"att\", \"i\", \"en\", \"jag\", \"hon\", \n",
        "                \"som\", \"han\", \"paa\", \"den\", \"med\", \"var\", \"sig\", \n",
        "                \"foer\", \"saa\", \"till\", \"aer\", \"men\", \"ett\", \n",
        "                \"om\", \"hade\", \"de\", \"av\", \"icke\", \"mig\", \"du\", \n",
        "                \"henne\", \"daa\", \"sin\", \"nu\", \"har\", \"inte\", \n",
        "                \"hans\", \"honom\", \"skulle\", \"hennes\", \"daer\", \n",
        "                \"min\", \"man\", \"ej\", \"vid\", \"kunde\", \"naagot\", \n",
        "                \"fraan\", \"ut\", \"naer\", \"efter\", \"upp\", \"vi\", \n",
        "                \"dem\", \"vara\", \"vad\", \"oever\", \"aen\", \"dig\", \n",
        "                \"kan\", \"sina\", \"haer\", \"ha\", \"mot\", \"alla\", \n",
        "                \"under\", \"naagon\", \"eller\", \"allt\", \"mycket\", \n",
        "                \"sedan\", \"ju\", \"denna\", \"sjaelv\", \"detta\", \n",
        "                \"aat\", \"utan\", \"varit\", \"hur\", \"ingen\", \"mitt\", \n",
        "                \"ni\", \"bli\", \"blev\", \"oss\", \"din\", \"dessa\", \n",
        "                \"naagra\", \"deras\", \"blir\", \"mina\", \"samma\", \n",
        "                \"vilken\", \"er\", \"saadan\", \"vaar\", \"blivit\", \n",
        "                \"dess\", \"inom\", \"mellan\", \"saadant\", \"varfoer\", \n",
        "                \"varje\", \"vilka\", \"ditt\", \"vem\", \"vilket\", \n",
        "                \"sitta\", \"saadana\", \"vart\", \"dina\", \"vars\", \n",
        "                \"vaart\", \"vaara\", \"ert\", \"era\", \"vilka\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDz3hdJXH6v2",
        "lang": "en"
      },
      "source": [
        "N√§r vi skapat v√•r lista √§r det dags att skapa en funktion som tar bort dessa fr√•n ett dokument. Denna funktion √§r kodad i cellen nedan. (Igen strunta i lambda f√∂r tillf√§llet.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNY7UKiwH6v2"
      },
      "outputs": [],
      "source": [
        "remove_stopwords = lambda x: ' '.join(y for y in x.split() if y not in my_stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtl8iWqcH6v2"
      },
      "source": [
        "Funktionen ovan tar allts√• bort stoppord fr√•n ett dokument (allts√• en tweet), f√∂r att ta bort stoppord fr√•n hela v√•rt corpus kan funktionen `.apply()`anv√§ndas. \n",
        "\n",
        "**F22.** Skriv den kod som tar bort alla stoppord fr√•n `tweets_low_no_small` och skapar en ny variabel `tweets_low_no_small_stopwords` f√∂r corpuset utan stoppord."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2tKbp4CH6v2"
      },
      "outputs": [],
      "source": [
        "tweets_low_no_small_stopwords = ...#din kod h√§r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ek7W9THH6v2"
      },
      "outputs": [],
      "source": [
        "top_words_low_no_small_stopwords = plot_top_words(tweets_low_no_small_stopwords, 50, 30)\n",
        "top_words_low_no_small_stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3UqdYh_H6v2"
      },
      "source": [
        "**F23.** Efter att stopporden tagits bort, hur m√•nga g√•nger m√•ste ett ord f√∂rekomma i v√•rt corpus f√∂r att hamna i den nya listan enligt ovan? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR-bM_xqH6v2",
        "lang": "en"
      },
      "source": [
        "**F24.** Vad √§r skillnaderna mellan de frekvent f√∂rekommande orden i j√§mf√∂relse med v√•ra tidigare listor? Skriv den kod som j√§mf√∂r dessa tre listor `top_words_lowered`, `top_words_low_no_small` and `top_words_low_no_small_stopwords`, titta p√• de f√∂rsta 20 orden i listorna.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwI63HRPH6v3",
        "lang": "en"
      },
      "source": [
        "### Visualisering och rekommendation\n",
        "\n",
        "Dags att visualisera v√•rt resultat och √∂vertyga v√•r klient om att vi hittat de b√§sta debatt√§mnena f√∂r dem! H√§r g√∂r vi det genom att skapa ett word cloud d√§r de mest frekventa orden syns b√§st. \n",
        "\n",
        "Nedanst√•ende kod skapar ett ordmoln f√∂r `top_words_low_no_small_stopwords`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIDAtPbCH6v3"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "wordcloud = WordCloud(max_font_size=40)\n",
        "wordcloud.fit_words(top_words_no_small_stopwords.to_dict())\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ixFS3QeH6v3"
      },
      "source": [
        "**F25** √Ñndra i tidigare kod hur m√•nga g√•nger ett ord minst m√•ste finnas f√∂r att det ska inkluderas i ordmolnet. Vad f√∂r√§ndras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkk5kNvGH6v3",
        "lang": "en"
      },
      "source": [
        "**F26** N√§r du tittar p√• ordmolnet, √§r det fler ord som borde vara stoppord? Ange n√•gra stycken och f√∂rklara varf√∂r de b√∂r tas bort."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_r02ky5H6v3",
        "lang": "en"
      },
      "source": [
        "**F27.** Vilket tema rekommenderar ni att publicisten ska ha som debatt√§mne? F√∂rklara svaret. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bux0fdKH6v3",
        "lang": "en"
      },
      "source": [
        "**F28.** Ni har nu arbetat med textdata, hur √§r det annorlunda n√§r det g√§ller pre-processing j√§mf√∂rt med annan typ av data som √§r av mer numerisk eller kategorisk karakt√§r?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe8QUGnDH6v3"
      },
      "source": [
        "---\n",
        "*N√§r ni besvarat samtliga fr√•gor och all er kod fungerar i enlighet med instruktioner, gl√∂m d√• inte commita er l√∂sning till GitHub och h√∂r sedan av er f√∂r muntlig redovisning.\n",
        "\n",
        "Lycka till!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3uAIDJZH6v4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nbTranslate": {
      "displayLangs": [],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "sv",
      "targetLang": "en",
      "useGoogleTranslate": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
